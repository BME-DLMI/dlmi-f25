{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lecture09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this assignment you will work with the basic building blocks of PyTorch, including tensors and autograd. To start with this will be very  low-level PyTorch, in future lectures we will get into the higher-level functionality of PyTorch which make it really easy to build and train neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install torchviz\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Initializing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Tensor from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(5.)\n",
    "vector = torch.tensor([5,4,3,2,1])\n",
    "matrix = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Tensor from NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "If you have data in a NumPy array, you can convert it to a PyTorch tensor using `torch.from_numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = np.array([[2,5],[6,4]])\n",
    "x_data = torch.from_numpy(data_np)\n",
    "\n",
    "print(f'data_np:\\n {data_np}')\n",
    "print(f'x_data:\\n {x_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Random Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The weights of a neural network are initalized with random values. PyTorch has `torch.rand` and `torch.randn` functions for generating random tensors with a specified size. For example `torch.rand(2,3)` will crate a tensor with size $2\\times3$ (2 rows, 3 columns). Below, create two tensors each with size $1000\\times500$, using `torch.rand` for one, and `torch.randn` for the other. After the tensors are initialized, plot histograms to show the distributions of each tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor = XXX\n",
    "randn_tensor = XXX\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "_ = ax[0].hist(torch.flatten(rand_tensor),bins=25,edgecolor='k')\n",
    "_ = ax[1].hist(torch.flatten(randn_tensor),bins=25,edgecolor='k')\n",
    "ax[0].set_title(\"torch.rand\")\n",
    "ax[1].set_title(\"torch.randn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "After viewing the histograms, what do you notice about the two distributions? What is the difference between `torch.rand` and `torch.randn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "PyTorch provides automatic differentiation (autograd) functionality, enabling gradients to be tracked on tensor operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f = (x+y)\\times z$$\n",
    "\n",
    "with $x=5$, $y=-2$, $z=4$, use autograd to compute \n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial f}{\\partial z}  \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "First, create and initalize tensors for $x$, $y$, $z$. Since the goal is to compute $\\nabla f$, make sure to use `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = XXX\n",
    "y = XXX\n",
    "z = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Note you can pass the `requires_grad=True` when creating a tensor **or** modify the `requires_grad` attribute after the tensor is created using the `requires_grad_(True)` member function of a tensor. Note pytorch uses the underscore at the end of a function for in-place operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Write the expression to compute $f$ using operations on the above tensors, i.e., the forward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = XXX\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "All tensors with `requires_grad=True` will have a `grad` attribute the gradient with respect to that tensor. Below try printing the `grad` value for each tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Currently, no values are stored in the `grad` attributes. The function $f$ has been evaluated (i.e., forward pass), however, the backward pass (which calculates gradients) has not been executed. The backward pass is executed by calling `backward()` on the tensor for which you are computing the gradient on. Here we want to take $\\nabla f$ so we call `f.backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Gradients are **accumulated** with each call of `backward()`. To see this, run the forward and backward pass again and print the gradient values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (x+y)*z\n",
    "f.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Typically, for training neural networks this is not the desired behavior. We want to use the gradients of only the current step, we do not want accumulate gradients over all steps. Therefore, it is neccessary to zero the gradients after each pass. Forgetting this is a common bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad.zero_()\n",
    "y.grad.zero_()\n",
    "z.grad.zero_()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(x = x, y = y, z = z)\n",
    "make_dot(f, params = params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Practice problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "For each practice problem:\n",
    "\n",
    "- Create and intiizlize input tensors\n",
    "- Evaluate function (forward pass)\n",
    "- Perform backward pass\n",
    "- Report gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f(x,y) = \\sqrt{x^2 + y^2}$$\n",
    "\n",
    "Compute \n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{bmatrix}$$\n",
    "\n",
    "Assume $x=4$, $y=3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f(a,x) = e^{-(ax)}$$\n",
    "\n",
    "Compute \n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial a} \\\\ \\frac{\\partial f}{\\partial x} \\end{bmatrix}$$\n",
    "\n",
    "Assume $a=2$, $x=-0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f(x,y,z) = \\frac{xy}{z}$$\n",
    "\n",
    "Compute \n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial f}{\\partial z} \\end{bmatrix}$$\n",
    "\n",
    "Assume $x=6$, $y=3$, $z=9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f(a,b,w_0, w_1, x_0, x_1) = a \\mathrm{ReLU}(w_0x_0) + \\mathrm{ReLU}(w_1x_1) - b$$\n",
    "\n",
    "Compute\n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial a} \\\\ \\frac{\\partial f}{\\partial b} \\\\ \\frac{\\partial f}{\\partial w_0} \\\\ \\frac{\\partial f}{\\partial w_1} \\\\ \\frac{\\partial f}{\\partial x_0} \\\\ \\frac{\\partial f}{\\partial x_1}\\end{bmatrix}$$\n",
    "\n",
    "Assume $a=2$, $b=6$, $w_0=3$,  $w_1=5$, $x_0=4$, $x_1=-2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Given the function\n",
    "\n",
    "$$f = ax^2 + bxy$$\n",
    "\n",
    "compute \n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial a} \\\\ \\frac{\\partial f}{\\partial b} \\\\ \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{bmatrix}$$\n",
    "\n",
    "Assume $a=2$, $b=4$, $x=3$, $y=5$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Save a PDF of the document to upload to ICON and then add/commit/push to your git repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
