{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lecture12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this assignment you will implement a 3D convolutional neural network (CNN) architecture.\n",
    "The CNN should have the following layers (listed in order):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "- **Input:** 3D tensor with size 128 x 256 x 256\n",
    "  \n",
    "- **Layer 0:** Max Pool 3D, downsampling **x4** in each spatial dimension\n",
    "\n",
    "- **Layer 1:** Convolution 3D (number of kernels = 8, kernel size: 3, stide: 1, zero padding)\n",
    "  \n",
    "- **Layer 2:** ReLU\n",
    "\n",
    "- **Layer 3:** Max Pool 3D (downsampling **x2** in each spatial dimension)\n",
    "\n",
    "- **Layer 4:** Convolution 3D (number of kernels = 16, kernel size: 5, stide: 1, zero padding)\n",
    "\n",
    "- **Layer 5:** ReLU\n",
    "\n",
    "- **Layer 6:** Max Pool 3D (downsampling **x4** in each spatial dimension)\n",
    "\n",
    "- **Layer 7:** Flatten to vector \n",
    "\n",
    "- **Layer 8:** Fully-connected, hidden units: 512\n",
    "\n",
    "- **Layer 9:** ReLU\n",
    "\n",
    "- **Layer 10:** Fully-connected, hidden units: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available.\")\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "engr_dir = \"/opt/nfsopt/DLMI\"\n",
    "idas_dir = os.path.join(os.path.expanduser('~'), \"classdata\")\n",
    "\n",
    "if os.path.isdir(engr_dir):\n",
    "    data_dir = engr_dir\n",
    "elif os.path.isdir(idas_dir):  \n",
    "    data_dir = idas_dir\n",
    "else:\n",
    "    print(\"Data directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Before implementing the CNN model in PyTorch, first calculate the output size of each layer and the number of learnable parameters associated with each layer. **This part should be completed by hand and upload as a separate PDF. Show all work.** Below enter the total number of learnable parameters calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Implement the above 3D CNN by creating a Python class which inherits from the `torch.nn.Module` class. Your class will need to implement the `__init__` and `forward` methods . The `__init__` method should just create instances of all layers, and the `forward` method should perform the forward pass by composing the layers together and returning the output. Refer to Lecture09 slides for a refresher on how to create a custom model using `torch.nn.Module`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    ######################################\n",
    "    #######         TODO           #######\n",
    "    ######################################\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Read an example MRI image to use for testing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(data_dir, \"lecture12\", \"mri.nii.gz\")\n",
    "im = sitk.ReadImage(fn)\n",
    "print(f'Image size: {im.GetSize()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Convert the SimpleITK image to a NumPy array and then convert it to a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#######         TODO           #######\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The 3D layers in Pytorch expect the input tensors to be 5D where the dimensions correspond to \n",
    "\n",
    "(batch, channels, size_k, size_j, size_i)\n",
    "\n",
    "\n",
    "In this example, both the batch and channel size will be 1 for the input, however, a placeholder/dummy dimension still needs to be created or Pytorch will throw an error. \n",
    "\n",
    "Calling `unsqueeze(dim)` on a tensor will create a new dimension (with size 1) at the specified `dim` position. Convert the above 3D tensor to the apporpirate 5D tensor. Additionally, convert the tensor data type to `float`. Print the resulting shape and data type to confirm the desired properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#######         TODO           #######\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Create an instance of the CNN class and peform a forward pass using the prepared tensor as input. To run on the GPU, you will need to put both the model and input tensor on the GPU before calling the forward pass using `to(device)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#######         TODO           #######\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Print the total number of learnable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total params: {num_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Save a PDF of the document to upload to ICON and then add/commit/push to your git repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
